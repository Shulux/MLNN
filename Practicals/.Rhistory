# Make predictions
preds3 <- predict(lda3)
# Calculate the confusion matrix
conf3 <- table(ltrs$lettr, preds3$class)
# Calculate the overall accuracy
# (hint consider the elements of the confusion matrix)
acc3 <- sum(diag(conf3))/sum(conf3)*100
acc3
# Calculate the precision for `A`
prec_a3 <- conf3[1,1]/(sum(conf3[, 1]))*100
prec_a3
# Calculate the recall for `A`
recall_a3 <- conf3[1,1]/(sum(conf3[1,]))*100
recall_a3
lda3
knitr::opts_chunk$set(echo = TRUE)
# Generate synthetic data
data <- data.frame(
x1 = rnorm(100),
x2 = rnorm(100),
x3 = rnorm(100))
data$y = data$x1 + 0.5*data$x2^2 +
(data$x3-0.1*data$x2)^3 + rnorm(100,0,0.1)
# Pairs plot
pairs(data)
data[c(1,2,3,4), ]
data-data[c(1,2,3,4), ]
data[-c(1,2,3,4), ]
?seq
seq(1, 80)
train_indices <- seq(1, 80)
data_train <- data[train_indices, ]
data_test <- data[-train_indices, ]
# Pairs plot colouring by training/test
pairs(data,
col = ifelse(1:nrow(data) %in% train_indices,
"blue", "red"))
sample(1:nrow(data), 0.8*nrow(data))
sample(1:nrow(data), 0.8*nrow(data))
sample(1:nrow(data), 0.8*nrow(data))
sample(1:nrow(data), 0.8*nrow(data))
# Split the data
train_indices <- sample(1:nrow(data), 0.8*nrow(data))
data_train <- data[train_indices, ]
data_test <- data[-train_indices, ]
# Pairs plot colouring by training/test
pairs(data,
col = ifelse(1:nrow(data) %in% train_indices,
"blue", "red"))
mean((data_train$y-predictions)^2)
# Fit a polynomial model
model <- lm(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data_train)
# Predict on the test data
predictions <- predict(model)
mean((data_train$y-predictions)^2)
# Calculate MSE
mse <- mean((data_train$y-predictions)^2)
mse
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
summary(model)$adj.r.squared
# Plot actual vs predictions
plot(data_train$y, predictions)
# Fit a polynomial model
model <- lm(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data_train)
# Predict on the test data
predictions <- predict(model)
# Calculate MSE
mse <- mean((data_train$y-predictions)^2)
mse
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
summary(model)$adj.r.squared
# Plot actual vs predictions
plot(data_train$y, predictions)
# Fit a polynomial model
model <- lm(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data_train)
# Predict on the test data
predictions <- predict(model, newdata = data_test)
# Calculate MSE
mse <- mean((data_test$y-predictions)^2)
mse
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
summary(model)$adj.r.squared
# Plot actual vs predictions
plot(data_test$y, predictions)
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
adj_r2 <- summary(model)$adj.r.squared
adj_r2
# Plot actual vs predictions
plot(data_test$y, predictions)
# Fit a polynomial model
model <- lm(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data_train)
# Predict on the test data
predictions <- predict(model, newdata = data_test)
# Calculate MSE
mse <- mean((data_test$y-predictions)^2)
mse
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
adj_r2 <- summary(model)$adj.r.squared
adj_r2
# Plot actual vs predictions
plot(data_test$y, predictions,
xlab = "Actual",
ylab = "Predicted",
xlim = c(min(data_test$y, predictions),
max(data_test$y, predictions)))
abline(a = 0, b = 1, col = "red")
# Fit a polynomial model
model <- lm(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data_train)
# Predict on the test data
predictions <- predict(model, newdata = data_test)
# Calculate MSE
mse <- mean((data_test$y - predictions)^2)
mse
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
adj_r2 <- summary(model)$adj.r.squared
adj_r2
# Plot actual vs predictions
plot(data_test$y, predictions,
xlab = "Actual",
ylab = "Predicted",
xlim = c(min(data_test$y, predictions),
max(data_test$y, predictions)),
ylim = c(min(data_test$y, predictions),
max(data_test$y, predictions)))
abline(a = 0, b = 1, col = "red")
install.packages(caret)
install.packages('caret')
knitr::opts_chunk$set(echo = TRUE)
# Load the caret package
library(caret)
?train
knitr::opts_chunk$set(echo = TRUE)
# Generate synthetic data
data <- data.frame(
x1 = rnorm(100),
x2 = rnorm(100),
x3 = rnorm(100))
data$y = data$x1 + 0.5*data$x2^2 +
(data$x3-0.1*data$x2)^3 + rnorm(100,0,0.1)
# Pairs plot
pairs(data)
# Split the data
train_indices <- sample(1:nrow(data), 0.8*nrow(data))
data_train <- data[train_indices, ]
data_test <- data[-train_indices, ]
# Pairs plot colouring by training/test
pairs(data,
col = ifelse(1:nrow(data) %in% train_indices,
"blue", "red"))
# Fit a polynomial model
model <- lm(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data_train)
# Predict on the test data
predictions <- predict(model, newdata = data_test)
# Calculate MSE
mse <- mean((data_test$y - predictions)^2)
mse
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
adj_r2 <- summary(model)$adj.r.squared
adj_r2
# Plot actual vs predictions
plot(data_test$y, predictions,
xlab = "Actual",
ylab = "Predicted",
xlim = c(min(data_test$y, predictions),
max(data_test$y, predictions)),
ylim = c(min(data_test$y, predictions),
max(data_test$y, predictions)))
abline(a = 0, b = 1, col = "red")
# Load the caret package
library(caret)
# Set up the cross-validation
control <- trainControl(method = "cv",
number = 5)
# Fit the model using cross-validation
model_cv <- train(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data,
method = "lm",
trControl = control)
# List the elements
names(model_cv)
# Extract the results
results <- model_cv$results
results
# Hence, calculate the MSE
mse <- results$RMSE^2
mse
# Make predictions on the "test" data
predictions_cv <- predict(model_cv,
newdata = data_test)
# Plot actual vs predictions
plot(data_test$y, predictions_cv,
xlab = "Actual",
ylab = "Predicted",
xlim = c(min(data_test$y, predictions_cv),
max(data_test$y, predictions_cv)),
ylim = c(min(data_test$y, predictions_cv),
max(data_test$y, predictions_cv)))
abline(a = 0, b = 1, col = "red")
# Overlay points from initial model
points(data_test$y, predictions, col = "lightblue")
# Set up the cross-validation
control <- trainControl(method = "LOOCV")
# Fit the model using leave-one-out cross-validation
model_loocv <- train(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data,
method = "lm",
trControl = control)
# Extract the results
model_loocv$results
# Calculate the MSE
mse <- model_loocv$results$RMSE^2
mse
?predict
knitr::opts_chunk$set(echo = TRUE)
# Generate synthetic data
data <- data.frame(
x1 = rnorm(100),
x2 = rnorm(100),
x3 = rnorm(100))
data$y = data$x1 + 0.5*data$x2^2 +
(data$x3-0.1*data$x2)^3 + rnorm(100,0,0.1)
# Pairs plot
pairs(data)
# Split the data
train_indices <- sample(1:nrow(data), 0.8*nrow(data))
data_train <- data[train_indices, ]
data_test <- data[-train_indices, ]
# Pairs plot colouring by training/test
pairs(data,
col = ifelse(1:nrow(data) %in% train_indices,
"blue", "red"))
# Fit a polynomial model
model <- lm(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data_train)
# Predict on the test data
predictions <- predict(model, newdata = data_test)
# Calculate MSE
mse <- mean((data_test$y - predictions)^2)
mse
# Calculate adjusted R-squared
# (Hint it has been calculated in the model summary)
adj_r2 <- summary(model)$adj.r.squared
adj_r2
# Plot actual vs predictions
plot(data_test$y, predictions,
xlab = "Actual",
ylab = "Predicted",
xlim = c(min(data_test$y, predictions),
max(data_test$y, predictions)),
ylim = c(min(data_test$y, predictions),
max(data_test$y, predictions)))
abline(a = 0, b = 1, col = "red")
# Load the caret package
library(caret)
# Set up the cross-validation
control <- trainControl(method = "cv",
number = 5)
# Fit the model using cross-validation
model_cv <- train(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data,
method = "lm",
trControl = control)
# List the elements
names(model_cv)
# Extract the results
results <- model_cv$results
results
# Hence, calculate the MSE
mse <- results$RMSE^2
mse
# Make predictions on the "test" data
predictions_cv <- predict(model_cv,
newdata = data_test)
# Plot actual vs predictions
plot(data_test$y, predictions_cv,
xlab = "Actual",
ylab = "Predicted",
xlim = c(min(data_test$y, predictions_cv),
max(data_test$y, predictions_cv)),
ylim = c(min(data_test$y, predictions_cv),
max(data_test$y, predictions_cv)))
abline(a = 0, b = 1, col = "red")
# Overlay points from initial model
points(data_test$y, predictions, col = "lightblue")
# Set up the cross-validation
control <- trainControl(method = "LOOCV")
# Fit the model using leave-one-out cross-validation
model_loocv <- train(y ~ poly(x1, 2) + poly(x2, 2) + poly(x3, 2),
data = data,
method = "lm",
trControl = control)
# Extract the results
model_loocv$results
# Calculate the MSE
mse <- model_loocv$results$RMSE^2
mse
# Make predictions on the "test" data
predictions_loocv <- predict(model_loocv, data_test)
# Plot actual vs predictions
plot(data_test$y, predictions_loocv,
xlab = "Actual",
ylab = "Predicted",
xlim = c(min(data_test$y, predictions_loocv),
max(data_test$y, predictions_loocv)),
ylim = c(min(data_test$y, predictions_loocv),
max(data_test$y, predictions_loocv)))
abline(0, 1, col="red")
# Overlay points from initial model
points(data_test$y, predictions, col="lightblue")
# Overlay points from 5-fold cross-validation
points(data_test$y, predictions_cv, col="lightgreen")
# Load the data
weather_full <- read.csv("https://www.maths.dur.ac.uk/users/john.p.gosling/MATH3431_practicals/weather_classification_data.csv")
# Display the first few rows
# Select the features of interest
weather <- weather_full[,c(8,1,3,4,6)]
# Convert the season to a factor
weather$Season <- as.factor(weather$Season)
# Summarise the data
# Split the data
#train_indices <-
#weather_train <-
#weather_test <-
# Fit a k-nearest neighbours model
#model_knn <- train(Season ~ .,
#                   data = ????,
#                   method = ????,
#                   trControl = trainControl(method = "cv",
#                                            number = 10))
# Extract the results
# Make predictions on the test data
# Calculate the confusion matrix
weather_full
str(weather_full
)
# Display the first few rows
head(weather_full)
# Display the first few rows
head(weather_full)
head(weather_full)
str(weather_full)
summary(weather_full)
# Select the features of interest
weather <- weather_full[ , c(8,1,3,4,6)]
# Convert the season to a factor
weather$Season <- as.factor(weather$Season)
weather
# Summarise the data
summary(weather)
str(weather)
head(weather)
head(weather)
sample(1:nrow(weather), nrow(weather))
# Split the data
train_indices <- sample(1:nrow(weather), 0.8*nrow(weather))
weather_train <- weather[train_indices, ]
weather_test <- weather[-train_indices, ]
# Fit a k-nearest neighbours model
model_knn <- train(Season ~ .,
data = weather_train,
method = "knn",
trControl = trainControl(method = "cv",
number = 10))
# Extract the results
model_knn$results
# Make predictions on the test data
predictions_knn_weather <- predict(model_knn, weather_test)
predictions_knn_weather
# Load the data
weather_full <- read.csv("https://www.maths.dur.ac.uk/users/john.p.gosling/MATH3431_practicals/weather_classification_data.csv")
# Display the first few rows
head(weather_full)
str(weather_full)
summary(weather_full)
# Select the features of interest
weather <- weather_full[ , c(8,1,3,4,6)]
# Convert the season to a factor
weather$Season <- as.factor(weather$Season)
# Summarise the data
summary(weather)
str(weather)
head(weather)
set.seed(123)
# Split the data
train_indices <- sample(1:nrow(weather), 0.8*nrow(weather))
weather_train <- weather[train_indices, ]
weather_test <- weather[-train_indices, ]
# Fit a k-nearest neighbours model
model_knn <- train(Season ~ .,
data = weather_train,
method = "knn",
trControl = trainControl(method = "cv",
number = 10))
# Extract the results
model_knn$results
# Make predictions on the test data
predictions_knn_weather <- predict(model_knn, weather_test)
# Calculate the confusion matrix
confusionMatrix(predictions_knn_weather,
weather_test$Season)
install.packages(naive_bayes)
install.packages(naivebayes)
install.packages("naivebayes")
# Fit a naive Bayes model
model_nb <- train(Season ~ .,
data = weather_train,
method = "naive_bayes",
trControl = trControl(method = "cv",
number = 10))
# Fit a naive Bayes model
model_nb <- train(Season ~ .,
data = weather_train,
method = "naive_bayes",
trControl = trainControl(method = "cv",
number = 10))
# Extract the results
model_nb$results
# Make predictions on the test data
predictions_nb <- predict(model_nb, weather_test)
# Calculate the confusion matrix
confusionMatrix(predictions_nb,
weather_test$Season)
# Pairs plot coloured by season
pairs(weather[sample(1:nrow(weather),1000),2:5],
col = weather_train$Season)
# Also consider the names of the full set of variables
names(weather_full)
install.packages("rpart")
# Load the data
mushroom <- read.csv("https://www.maths.dur.ac.uk/users/john.p.gosling/MATH3431_practicals/mushrooms.csv")
# Display the first few rows
head(mushroom)
# Convert all variables to factors and put back into the data frame
mushroom <- lapply(mushroom, as.factor)
mushroom <- as.data.frame(mushroom)
# Remove all but the first four predictors
# to aid interpretation of the tree
mushroom <- mushroom[,1:5]
# Summarise the data
summary(mushroom)
str(mushroom)
head(mushroom)
# Load the `rpart` package
library(rpart)
train_indices <- sample(1:nrow(mushroom), 0.8*nrow(mushroom))
mushroom_train <- mushroom[train_indices, ]
mushroom_test <- mushroom[-train_indices, ]
# Load the `rpart.plot` package
library(rpart.plot)
# Fit a naive Bayes model
model_nb <- train(Season ~ .,
data = weather_train,
method = "naive_bayes",
trControl = trainControl(method = "cv",
number = 10))
# Extract the results
model_nb$results
# Make predictions on the test data
predictions_nb <- predict(model_nb, weather_test)
# Calculate the confusion matrix
confusionMatrix(predictions_nb,
weather_test$Season)
# Pairs plot coloured by season
pairs(weather[sample(1:nrow(weather),1000),2:5],
col = weather_train$Season)
# Also consider the names of the full set of variables
names(weather_full)
# Load the data
mushroom <- read.csv("https://www.maths.dur.ac.uk/users/john.p.gosling/MATH3431_practicals/mushrooms.csv")
# Display the first few rows
head(mushroom)
# Convert all variables to factors and put back into the data frame
mushroom <- lapply(mushroom, as.factor)
mushroom <- as.data.frame(mushroom)
# Remove all but the first four predictors
# to aid interpretation of the tree
mushroom <- mushroom[,1:5]
# Summarise the data
summary(mushroom)
str(mushroom)
head(mushroom)
# Load the `rpart` package
library(rpart)
# Fit a decision tree using 5-fold cross-validation
model_tree <- train(class ~ .,
data = mushroom,
method = "rpart",
trControl = trainControl(method = "cv",
number = 5))
# Load the `rpart.plot` package
library(rpart.plot)
# Plot the tree
rpart.plot(model_tree$finalModel)
mushroom[-1, ]
mushroom[sample(1:nrow(mushroom), 1), ]
str(mushroom)
mushroom[sample(1:nrow(mushroom), 1), ]
mushroom[sample(1:nrow(mushroom), 1), ]
mushroom[sample(1:nrow(mushroom), 1), ]
